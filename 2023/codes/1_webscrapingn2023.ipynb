{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RgLsCp_3Ufw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "LBaJDYhE3GGe",
        "outputId": "640c08ab-095a-4619-e4c7-7121e0b60457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Descargando salud: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.74it/s]\n",
            "Descargando nutricion: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:16<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßπ SALUD ‚Üí CSV: renombrados 0, gunzip 0 | CAT: renombrados 0, gunzip 0\n",
            "\n",
            "üßπ NUTRICION ‚Üí CSV: renombrados 0, gunzip 0 | CAT: renombrados 0, gunzip 0\n",
            "\n",
            "‚úÖ Resumen descargas:\n",
            "   salud: CSV=7  |  CAT=7\n",
            "   nutricion: CSV=28  |  CAT=28\n",
            "\n",
            "üìÇ Ra√≠z: /content/ensanut_2023\n",
            "   salud ‚Üí csv: /content/ensanut_2023/salud/csv  |  catalogos: /content/ensanut_2023/salud/catalogos\n",
            "   nutricion ‚Üí csv: /content/ensanut_2023/nutricion/csv  |  catalogos: /content/ensanut_2023/nutricion/catalogos\n",
            "\n",
            "üóúÔ∏è ZIP final listo: /content/ensanut_2023_ALL.zip\n",
            "üì¶ Archivos en /content (deber√≠a verse solo el ZIP final o lo m√≠nimo):\n",
            "['/content/ensanut_2023_ALL.zip']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27edcf2c-1339-4e56-b662-69d411af0bf6\", \"ensanut_2023_ALL.zip\", 167302396)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip -q install bs4 lxml tqdm\n",
        "\n",
        "import os, re, requests, zipfile, shutil, gzip\n",
        "from urllib.parse import urljoin\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "# ========= Config =========\n",
        "BASE = \"https://ensanut.insp.mx/encuestas/ensanutcontinua2023/descargas.php\"\n",
        "ROOT = \"/content/ensanut_2023\"\n",
        "OUT = {\n",
        "    \"salud\":     {\"csv\": f\"{ROOT}/salud/csv\",     \"cat\": f\"{ROOT}/salud/catalogos\"},\n",
        "    \"nutricion\": {\"csv\": f\"{ROOT}/nutricion/csv\", \"cat\": f\"{ROOT}/nutricion/catalogos\"},\n",
        "}\n",
        "for comp in OUT:\n",
        "    os.makedirs(OUT[comp][\"csv\"], exist_ok=True)\n",
        "    os.makedirs(OUT[comp][\"cat\"], exist_ok=True)\n",
        "\n",
        "# ========= Utils =========\n",
        "def safe(s):\n",
        "    s = re.sub(r\"\\s+\", \" \", (s or \"\").strip())\n",
        "    s = re.sub(r\"[^\\w\\-.() √°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë]\", \"_\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return (s[:200] or \"sin_nombre\")\n",
        "\n",
        "def unique_path(folder, filename):\n",
        "    base, ext = os.path.splitext(filename)\n",
        "    i = 1\n",
        "    path = os.path.join(folder, filename)\n",
        "    while os.path.exists(path):\n",
        "        path = os.path.join(folder, f\"{base}__{i}{ext}\")\n",
        "        i += 1\n",
        "    return path\n",
        "\n",
        "def save_resp(resp, hint, folder):\n",
        "    cd = resp.headers.get(\"content-disposition\",\"\")\n",
        "    m = re.search(r'filename\\*?=(?:UTF-8\\'\\')?\"?([^\";]+)\"?', cd)\n",
        "    fn = m.group(1) if m else os.path.basename(hint) or \"archivo.bin\"\n",
        "    fn = safe(fn)\n",
        "    path = unique_path(folder, fn)\n",
        "    with open(path, \"wb\") as f:\n",
        "        for chunk in resp.iter_content(1<<14):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    return path\n",
        "\n",
        "def extract_zip_to_folder(zip_path: Path, dest_folder: Path):\n",
        "    extracted = []\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        for member in zf.infolist():\n",
        "            if member.is_dir():\n",
        "                continue\n",
        "            base_name = safe(Path(member.filename).name)\n",
        "            out_path = Path(unique_path(str(dest_folder), base_name))\n",
        "            with zf.open(member) as src, open(out_path, \"wb\") as dst:\n",
        "                shutil.copyfileobj(src, dst)\n",
        "            extracted.append(str(out_path))\n",
        "    zip_path.unlink(missing_ok=True)\n",
        "    return extracted\n",
        "\n",
        "def postprocess_unzip_all(dest_folder: str):\n",
        "    dest = Path(dest_folder)\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for z in list(dest.rglob(\"*.zip\")):\n",
        "            if zipfile.is_zipfile(z):\n",
        "                extract_zip_to_folder(z, dest)\n",
        "                changed = True\n",
        "\n",
        "def normalize_and_gunzip(folder: str):\n",
        "    folder_p = Path(folder)\n",
        "    fixed = gunzipped = 0\n",
        "\n",
        "    # Descomprimir .gz\n",
        "    for p in list(folder_p.rglob(\"*.gz\")):\n",
        "        low = p.name.lower()\n",
        "        if low.endswith(\".csv.gz\") or low.endswith(\".xlsx.gz\"):\n",
        "            target = p.with_suffix(\"\")  # quita .gz\n",
        "            target = Path(unique_path(str(target.parent), target.name))\n",
        "            with gzip.open(p, \"rb\") as src, open(target, \"wb\") as dst:\n",
        "                shutil.copyfileobj(src, dst)\n",
        "            p.unlink(missing_ok=True)\n",
        "            gunzipped += 1\n",
        "\n",
        "    # Arreglar dobles extensiones\n",
        "    for p in list(folder_p.rglob(\"*\")):\n",
        "        if not p.is_file():\n",
        "            continue\n",
        "        name_low = p.name.lower()\n",
        "        if name_low.endswith(\".csv.csv\"):\n",
        "            new_name = re.sub(r\"(?i)\\.csv\\.csv$\", \".csv\", p.name)\n",
        "            new_path = Path(unique_path(str(p.parent), new_name))\n",
        "            p.rename(new_path); fixed += 1\n",
        "        if name_low.endswith(\".xlsx.xlsx\"):\n",
        "            new_name = re.sub(r\"(?i)\\.xlsx\\.xlsx$\", \".xlsx\", p.name)\n",
        "            new_path = Path(unique_path(str(p.parent), new_name))\n",
        "            p.rename(new_path); fixed += 1\n",
        "\n",
        "    return fixed, gunzipped\n",
        "\n",
        "def zip_dir_stored(src_dir: str, zip_path: str):\n",
        "    src = Path(src_dir)\n",
        "    with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_STORED) as zf:\n",
        "        for p in src.rglob(\"*\"):\n",
        "            if p.is_file():\n",
        "                zf.write(p, arcname=p.relative_to(src))\n",
        "\n",
        "# ========= Session =========\n",
        "session = requests.Session()\n",
        "session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
        "\n",
        "# ========= Fetch & parse =========\n",
        "r = session.get(BASE, timeout=30)\n",
        "r.raise_for_status()\n",
        "soup = BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "# Localiza las dos secciones por su t√≠tulo\n",
        "sections = []\n",
        "for sec in soup.select(\"div.block-section\"):\n",
        "    h4 = sec.find(\"h4\", class_=\"block-title\")\n",
        "    title = (h4.get_text(strip=True) if h4 else \"\").upper()\n",
        "    if \"COMPONENTE DE SALUD\" in title:\n",
        "        comp = \"salud\"\n",
        "    elif \"COMPONENTE DE NUTRICI√ìN\" in title or \"COMPONENTE DE NUTRICION\" in title:\n",
        "        comp = \"nutricion\"\n",
        "    else:\n",
        "        continue\n",
        "    table = sec.find(\"table\")\n",
        "    if table:\n",
        "        sections.append((comp, table))\n",
        "\n",
        "if not sections:\n",
        "    raise SystemExit(\"No se detectaron tablas de SALUD/NUTRICI√ìN\")\n",
        "\n",
        "# ========= Download loop por componente =========\n",
        "stats = { \"salud\": {\"csv\":0, \"cat\":0}, \"nutricion\":{\"csv\":0, \"cat\":0} }\n",
        "\n",
        "for comp, table in sections:\n",
        "    rows = table.select(\"tbody tr\")\n",
        "    for i, row in enumerate(tqdm(rows, desc=f\"Descargando {comp}\")):\n",
        "        tds = row.find_all(\"td\")\n",
        "        if len(tds) < 6:\n",
        "            continue\n",
        "        categoria = safe(tds[0].get_text(\" \", strip=True) or f\"categoria_{i:03d}\")\n",
        "\n",
        "        # ----- CSV (columna 3) -----\n",
        "        td_csv = tds[3]\n",
        "        a_csv = td_csv.find(\"a\", href=True)\n",
        "        btn_csv = td_csv.find(\"button\", attrs={\"type\":\"submit\"})\n",
        "        try:\n",
        "            if a_csv:\n",
        "                url = urljoin(BASE, a_csv[\"href\"])\n",
        "                resp = session.get(url, stream=True, timeout=180, headers={\"Referer\": BASE})\n",
        "                resp.raise_for_status()\n",
        "                if \"text/html\" not in resp.headers.get(\"content-type\",\"\").lower():\n",
        "                    hint = a_csv.get(\"href\") or f\"{categoria}.csv\"\n",
        "                    save_resp(resp, hint, OUT[comp][\"csv\"])\n",
        "                    stats[comp][\"csv\"] += 1\n",
        "            elif btn_csv and btn_csv.has_attr(\"name\"):\n",
        "                payload = { btn_csv[\"name\"]: btn_csv.get(\"value\",\"\") }\n",
        "                resp = session.post(BASE, data=payload, stream=True, timeout=180, headers={\"Referer\": BASE})\n",
        "                resp.raise_for_status()\n",
        "                if \"text/html\" not in resp.headers.get(\"content-type\",\"\").lower():\n",
        "                    hint = btn_csv.get(\"title\", f\"{categoria}.csv\")\n",
        "                    save_resp(resp, hint, OUT[comp][\"csv\"])\n",
        "                    stats[comp][\"csv\"] += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[CSV:{comp}] {categoria}: {e}\")\n",
        "\n",
        "        # ----- Cat√°logo (columna 5) -----\n",
        "        td_cat = tds[5]\n",
        "        a_cat = td_cat.find(\"a\", href=True)\n",
        "        btn_cat = td_cat.find(\"button\", attrs={\"type\":\"submit\"})\n",
        "        try:\n",
        "            if a_cat:\n",
        "                url = urljoin(BASE, a_cat[\"href\"])\n",
        "                resp = session.get(url, stream=True, timeout=180, headers={\"Referer\": BASE})\n",
        "                resp.raise_for_status()\n",
        "                if \"text/html\" not in resp.headers.get(\"content-type\",\"\").lower():\n",
        "                    hint = a_cat.get(\"href\") or f\"{categoria}.xlsx\"\n",
        "                    save_resp(resp, hint, OUT[comp][\"cat\"])\n",
        "                    stats[comp][\"cat\"] += 1\n",
        "            elif btn_cat and btn_cat.has_attr(\"name\"):\n",
        "                payload = { btn_cat[\"name\"]: btn_cat.get(\"value\",\"\") }\n",
        "                resp = session.post(BASE, data=payload, stream=True, timeout=180, headers={\"Referer\": BASE})\n",
        "                resp.raise_for_status()\n",
        "                if \"text/html\" not in resp.headers.get(\"content-type\",\"\").lower():\n",
        "                    hint = btn_cat.get(\"title\", f\"{categoria}.xlsx\")\n",
        "                    save_resp(resp, hint, OUT[comp][\"cat\"])\n",
        "                    stats[comp][\"cat\"] += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[CAT:{comp}] {categoria}: {e}\")\n",
        "\n",
        "# ========= Unzip / gunzip / normaliza nombres por carpeta =========\n",
        "for comp in OUT:\n",
        "    postprocess_unzip_all(OUT[comp][\"csv\"])\n",
        "    postprocess_unzip_all(OUT[comp][\"cat\"])\n",
        "    fixed_csv, gunz_csv = normalize_and_gunzip(OUT[comp][\"csv\"])\n",
        "    fixed_cat, gunz_cat = normalize_and_gunzip(OUT[comp][\"cat\"])\n",
        "    print(f\"\\nüßπ {comp.upper()} ‚Üí CSV: renombrados {fixed_csv}, gunzip {gunz_csv} | CAT: renombrados {fixed_cat}, gunzip {gunz_cat}\")\n",
        "\n",
        "print(\"\\n‚úÖ Resumen descargas:\")\n",
        "for comp in stats:\n",
        "    print(f\"   {comp}: CSV={stats[comp]['csv']}  |  CAT={stats[comp]['cat']}\")\n",
        "print(\"\\nüìÇ Ra√≠z:\", ROOT)\n",
        "for comp in OUT:\n",
        "    print(f\"   {XD} ‚Üí csv: {OUT[comp]['csv']}  |  catalogos: {OUT[comp]['cat']}\")\n",
        "\n",
        "# ========= ZIPs por componente =========\n",
        "zip_paths = {}\n",
        "for comp in OUT:\n",
        "    zip_csv = f\"/content/ensanut_2023_{comp}_csv.zip\"\n",
        "    zip_cat = f\"/content/ensanut_2023_{comp}_catalogos.zip\"\n",
        "    zip_dir_stored(OUT[comp][\"csv\"], zip_csv)\n",
        "    zip_dir_stored(OUT[comp][\"cat\"], zip_cat)\n",
        "    zip_paths[(comp,\"csv\")] = zip_csv\n",
        "    zip_paths[(comp,\"cat\")] = zip_cat\n",
        "    print(f\"\\nüóúÔ∏è {comp.upper()} ZIPs:\")\n",
        "    print(\"   -\", zip_csv)\n",
        "    print(\"   -\", zip_cat)\n",
        "\n",
        "# ========= Descarga a tu equipo (Colab) =========\n",
        "try:\n",
        "    from google.colab import files\n",
        "    for (comp, kind), z in zip_paths.items():\n",
        "        if any(Path(OUT[comp][ \"csv\" if kind==\"csv\" else \"cat\"]).glob(\"*\")):\n",
        "            files.download(z)\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c95WVxJq5BDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}